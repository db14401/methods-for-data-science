{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xHSx8l1tUYN"
   },
   "source": [
    "<a name=\"outline\"></a>\n",
    "\n",
    "## Outline\n",
    "\n",
    "- [Task 1](#task-1): Regression\n",
    "  - [1.1](#q11) Linear regression\n",
    "  - [1.2](#q12) Ridge regression\n",
    "  - [1.3](#q13) Relaxation of Lasso regression\n",
    "- [Task 2](#task-2): Classification\n",
    "  - [2.1](#q21) kNN classifier\n",
    "  - [2.2](#q22) Random forest \n",
    "  - [2.3](#q23) Support vector machine (SVM) \n",
    "- [Task 3](#task-3): Mastery component \n",
    "  - [3.1](#q31) Logistic regression and bagging \n",
    "  - [3.2](#q32) Kernelised SVM classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3sSxTA3yzhN"
   },
   "source": [
    "<a name=\"task-1\"></a>\n",
    "# Task 1: Regression [^](#outline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gY8lFgnyzsF"
   },
   "source": [
    "<a name=\"q11\"></a>\n",
    "\n",
    "## 1.1  [^](#outline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.1\n",
    "\n",
    "I have extracted the data from csv file 'chemistry_samples' using pandas. I have then analysed the data to understand the format in which it is presented. This is important if the data contains any date columns as they will need to be parsed, but also for calculations, to know which columns can be used as numerical and others and categorical. I do this through firstly looking at the first 5 rows of the data. This will most likely give me most of the information I need to understand the data given, however there could be other rows further in the data that don't match the same as the first 5 and such can perform some more analysis to make sure our first glance is correct. I then run some analysis on the actual data provided to find the data types of the values. This allows me to see if the pattern I had spotted earlier was true, and from the output we can see that all the columns are all floating point values, and such can be treated numerically. This also confirms that no where within the data we have mistakes with letters creaping into the data which would need to be filtered to allow for the regression to continue. I have also calculated some basic statistics for each of the columns values. This is important to give me  quick summary of the data given. This allows me to see if there are any anomalies within the data, and also gives me the number of entries for each of the columns, which are all equal to one another, and with another analysis on the line below showing the shape of the data, confirms that every row is filled with all the variables, and such is a complete data set.\n",
    "\n",
    "Then I implemented standard linear regression using just the variables given. This gives me 10 beta values whcih correspond to the variables given, to predict the LC50 value.  Using these values I then test this against the training data to get an $R^2$ score, and display the beta coefficients found. I have printed this below. The $R^2$ score is a statistical measure for a regression model that represents the proportion of variance in the variables given that can be explained by the LC50 variable. This means that a higher $R^2$ score represents a better fitted model to the data. We can see that it returns an $R^2$ score of 0.77, which means that the regression found is quite a good fit, with a score of 0 being a horizontal line through the mean of the LC50 variable.\n",
    "\n",
    "I then implemented the augmented linear regression with an added intercept parameter. I do this as the data may not be normed to go exactly through the orgin, but the first regression method I implemented is limited to having to go through the origin. So by adding this intercept parameter, it enables the augmented linear regression to improve from the original regression, or if the data is normed, remain the same. By adding this intercept it solves the problem of data not normed through the origin, and as such I implemented the augmented linear regression below and compared the results. I calculated the $R^2$ score and displayed the augmented beta parameters found. They are presented below. This time the $R^2$ score is 0.87 which means that for the training data, this is a much better fit than the original regression implemented. However, this will need to be confirmed with unseen test data as it could be overfitting the training data and not fit the global pattern. However, this improved $R^2$ score will be the cause that the Intercept parameter added is not equal to 0, and such suggests that target data is not normalised and such the augmented linear regression is better suited for this problem. I have also compared the two methods in a data frame at the end, which allows me to see how the two methods differ in importance of the variables when the intercept parameter is added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as pandas data frames\n",
    "chemistry_samples = pd.read_csv('chemistry_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>NdssC</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>FV1</th>\n",
       "      <th>VFV</th>\n",
       "      <th>FV2</th>\n",
       "      <th>FV3</th>\n",
       "      <th>LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.661280</td>\n",
       "      <td>0.658363</td>\n",
       "      <td>1.602232</td>\n",
       "      <td>1.994272</td>\n",
       "      <td>0.836488</td>\n",
       "      <td>3.153623</td>\n",
       "      <td>15.893033</td>\n",
       "      <td>-27.724370</td>\n",
       "      <td>0.059355</td>\n",
       "      <td>0.756698</td>\n",
       "      <td>5.506249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.936362</td>\n",
       "      <td>1.154287</td>\n",
       "      <td>1.146997</td>\n",
       "      <td>0.904295</td>\n",
       "      <td>2.948308</td>\n",
       "      <td>5.141095</td>\n",
       "      <td>13.590177</td>\n",
       "      <td>-31.821521</td>\n",
       "      <td>-13.408855</td>\n",
       "      <td>1.161298</td>\n",
       "      <td>6.636791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964144</td>\n",
       "      <td>0.415485</td>\n",
       "      <td>1.481028</td>\n",
       "      <td>2.136585</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>-1.156783</td>\n",
       "      <td>15.989419</td>\n",
       "      <td>-3.699312</td>\n",
       "      <td>2.561525</td>\n",
       "      <td>0.500115</td>\n",
       "      <td>1.563388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.074617</td>\n",
       "      <td>1.417296</td>\n",
       "      <td>0.486216</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.066980</td>\n",
       "      <td>2.610960</td>\n",
       "      <td>7.962046</td>\n",
       "      <td>-16.374439</td>\n",
       "      <td>2.448975</td>\n",
       "      <td>1.481888</td>\n",
       "      <td>6.248432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.448569</td>\n",
       "      <td>0.836892</td>\n",
       "      <td>1.951012</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>-0.039121</td>\n",
       "      <td>1.851095</td>\n",
       "      <td>22.285266</td>\n",
       "      <td>-9.526361</td>\n",
       "      <td>2.870400</td>\n",
       "      <td>0.649234</td>\n",
       "      <td>3.676796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIC0  SM1_Dz(Z)    GATS1i     NdsCH     NdssC     MLOGP        FV1  \\\n",
       "0  3.661280   0.658363  1.602232  1.994272  0.836488  3.153623  15.893033   \n",
       "1  3.936362   1.154287  1.146997  0.904295  2.948308  5.141095  13.590177   \n",
       "2  0.964144   0.415485  1.481028  2.136585  0.043679 -1.156783  15.989419   \n",
       "3  2.074617   1.417296  0.486216  0.000908 -0.066980  2.610960   7.962046   \n",
       "4  1.448569   0.836892  1.951012  0.028318 -0.039121  1.851095  22.285266   \n",
       "\n",
       "         VFV        FV2       FV3      LC50  \n",
       "0 -27.724370   0.059355  0.756698  5.506249  \n",
       "1 -31.821521 -13.408855  1.161298  6.636791  \n",
       "2  -3.699312   2.561525  0.500115  1.563388  \n",
       "3 -16.374439   2.448975  1.481888  6.248432  \n",
       "4  -9.526361   2.870400  0.649234  3.676796  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIC0         float64\n",
       "SM1_Dz(Z)    float64\n",
       "GATS1i       float64\n",
       "NdsCH        float64\n",
       "NdssC        float64\n",
       "MLOGP        float64\n",
       "FV1          float64\n",
       "VFV          float64\n",
       "FV2          float64\n",
       "FV3          float64\n",
       "LC50         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_samples.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>NdssC</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>FV1</th>\n",
       "      <th>VFV</th>\n",
       "      <th>FV2</th>\n",
       "      <th>FV3</th>\n",
       "      <th>LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "      <td>4111.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.907930</td>\n",
       "      <td>0.635057</td>\n",
       "      <td>1.295748</td>\n",
       "      <td>0.449253</td>\n",
       "      <td>0.540840</td>\n",
       "      <td>2.093087</td>\n",
       "      <td>15.057563</td>\n",
       "      <td>-22.111122</td>\n",
       "      <td>0.302976</td>\n",
       "      <td>0.637047</td>\n",
       "      <td>4.139930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.782757</td>\n",
       "      <td>0.427101</td>\n",
       "      <td>0.396828</td>\n",
       "      <td>0.697176</td>\n",
       "      <td>0.940516</td>\n",
       "      <td>1.447468</td>\n",
       "      <td>3.539621</td>\n",
       "      <td>7.110208</td>\n",
       "      <td>5.239923</td>\n",
       "      <td>0.459752</td>\n",
       "      <td>1.206448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.508140</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.289772</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.600682</td>\n",
       "      <td>-3.505785</td>\n",
       "      <td>4.715537</td>\n",
       "      <td>-50.284071</td>\n",
       "      <td>-35.369667</td>\n",
       "      <td>-0.162048</td>\n",
       "      <td>0.124518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.324115</td>\n",
       "      <td>0.286364</td>\n",
       "      <td>0.965427</td>\n",
       "      <td>0.054057</td>\n",
       "      <td>-0.056750</td>\n",
       "      <td>1.141446</td>\n",
       "      <td>12.342002</td>\n",
       "      <td>-26.996891</td>\n",
       "      <td>-1.033571</td>\n",
       "      <td>0.285723</td>\n",
       "      <td>3.348342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.918325</td>\n",
       "      <td>0.560186</td>\n",
       "      <td>1.261636</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.116859</td>\n",
       "      <td>2.064408</td>\n",
       "      <td>14.707910</td>\n",
       "      <td>-22.326363</td>\n",
       "      <td>2.361851</td>\n",
       "      <td>0.536016</td>\n",
       "      <td>4.083925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.438485</td>\n",
       "      <td>0.900059</td>\n",
       "      <td>1.556928</td>\n",
       "      <td>0.860789</td>\n",
       "      <td>0.978137</td>\n",
       "      <td>3.022278</td>\n",
       "      <td>17.391135</td>\n",
       "      <td>-16.808405</td>\n",
       "      <td>3.287077</td>\n",
       "      <td>0.890875</td>\n",
       "      <td>4.901910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.286216</td>\n",
       "      <td>2.221232</td>\n",
       "      <td>2.950545</td>\n",
       "      <td>4.295030</td>\n",
       "      <td>6.328623</td>\n",
       "      <td>6.845000</td>\n",
       "      <td>31.153722</td>\n",
       "      <td>0.038877</td>\n",
       "      <td>5.981860</td>\n",
       "      <td>3.447559</td>\n",
       "      <td>8.751823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CIC0    SM1_Dz(Z)       GATS1i        NdsCH        NdssC  \\\n",
       "count  4111.000000  4111.000000  4111.000000  4111.000000  4111.000000   \n",
       "mean      2.907930     0.635057     1.295748     0.449253     0.540840   \n",
       "std       0.782757     0.427101     0.396828     0.697176     0.940516   \n",
       "min       0.508140     0.000209     0.289772     0.000158    -0.600682   \n",
       "25%       2.324115     0.286364     0.965427     0.054057    -0.056750   \n",
       "50%       2.918325     0.560186     1.261636     0.122348     0.116859   \n",
       "75%       3.438485     0.900059     1.556928     0.860789     0.978137   \n",
       "max       6.286216     2.221232     2.950545     4.295030     6.328623   \n",
       "\n",
       "             MLOGP          FV1          VFV          FV2          FV3  \\\n",
       "count  4111.000000  4111.000000  4111.000000  4111.000000  4111.000000   \n",
       "mean      2.093087    15.057563   -22.111122     0.302976     0.637047   \n",
       "std       1.447468     3.539621     7.110208     5.239923     0.459752   \n",
       "min      -3.505785     4.715537   -50.284071   -35.369667    -0.162048   \n",
       "25%       1.141446    12.342002   -26.996891    -1.033571     0.285723   \n",
       "50%       2.064408    14.707910   -22.326363     2.361851     0.536016   \n",
       "75%       3.022278    17.391135   -16.808405     3.287077     0.890875   \n",
       "max       6.845000    31.153722     0.038877     5.981860     3.447559   \n",
       "\n",
       "              LC50  \n",
       "count  4111.000000  \n",
       "mean      4.139930  \n",
       "std       1.206448  \n",
       "min       0.124518  \n",
       "25%       3.348342  \n",
       "50%       4.083925  \n",
       "75%       4.901910  \n",
       "max       8.751823  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4111, 11)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_lik_estimate(X, y):\n",
    "    \n",
    "    # X: N x D matrix of training inputs\n",
    "    # y: N x 1 vector of training targets/observations\n",
    "    # returns: maximum likelihood parameters (D x 1)\n",
    "    \n",
    "    N, D = X.shape\n",
    "    beta_ml = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "    return beta_ml\n",
    "\n",
    "\n",
    "def predict_with_estimate(X_test, beta):\n",
    "    \n",
    "    # X_test: K x D matrix of test inputs\n",
    "    # beta: D x 1 vector of parameters\n",
    "    # returns: prediction of f(X_test); K x 1 vector\n",
    "    \n",
    "    prediction = X_test @ beta\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train set\n",
    "chem_train = chemistry_samples.iloc[:, :-1].values\n",
    "\n",
    "# define the train target values\n",
    "chem_train_y = chemistry_samples.iloc[:, -1].values\n",
    "\n",
    "# work out the maximum likelihood estimates\n",
    "chem_train_beta_ml = max_lik_estimate(chem_train, chem_train_y)\n",
    "\n",
    "# predict the function values at the test points using the maximum likelihood estimator\n",
    "chem_train_ml_prediction_y = predict_with_estimate(chem_train, chem_train_beta_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score(y_test, y_pred):\n",
    "    \n",
    "    # y_test: N x 1 vector of actual values\n",
    "    # y_pred: N x 1 vector of predicted values\n",
    "    # returns: r2 score of the predictions\n",
    "\n",
    "    numerator = np.sum((y_test-y_pred)**2)\n",
    "    y_avg = np.mean(y_test)\n",
    "    denominator = np.sum((y_test-y_avg)**2)\n",
    "    \n",
    "    return 1 - numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.7712119635266652\n"
     ]
    }
   ],
   "source": [
    "print(r'R2 score:', r2_score(chem_train_y, chem_train_ml_prediction_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CIC0', 0.6203733928550708),\n",
       " ('SM1_Dz(Z)', 1.6806804178200736),\n",
       " ('GATS1i', -0.5661420478588721),\n",
       " ('NdsCH', 0.41624127447550235),\n",
       " ('NdssC', 0.06372340713960672),\n",
       " ('MLOGP', 0.430638221079959),\n",
       " ('FV1', 0.05704399647373448),\n",
       " ('VFV', 0.0012511248583359053),\n",
       " ('FV2', 0.01427984772537641),\n",
       " ('FV3', -0.01916889608754055)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(j, chem_train_beta_ml[i]) for i, j in enumerate(chemistry_samples.columns[:-1].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_lik_estimate_aug(X_aug, y):\n",
    "    \n",
    "    # X_aug: N x D+1 matrix of training inputs\n",
    "    # y: N x 1 vector of training targets/observations\n",
    "    # returns: maximum likelihood parameters (D+1 x 1)\n",
    "    \n",
    "    beta_aug_ml = max_lik_estimate(X_aug, y)\n",
    "    \n",
    "    return beta_aug_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train set\n",
    "chem_train = chemistry_samples.iloc[:, :-1].values\n",
    "\n",
    "# define the augmented train set \n",
    "chem_train_aug = np.hstack([np.ones((chem_train.shape[0],1)), chem_train])\n",
    "\n",
    "# define the train target values\n",
    "chem_train_y = chemistry_samples.iloc[:, -1].values\n",
    "\n",
    "# work out the augmented maximum likelihood estimates\n",
    "chem_train_aug_beta_ml = max_lik_estimate_aug(chem_train_aug, chem_train_y)\n",
    "\n",
    "# predict the function values at the test points using the augmented maximum likelihood estimator\n",
    "chem_train_aug_ml_prediction_y = predict_with_estimate(chem_train_aug, chem_train_aug_beta_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.8718259975718016\n"
     ]
    }
   ],
   "source": [
    "print(r'R2 score:', r2_score(chem_train_y, chem_train_aug_ml_prediction_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Intercept', 2.6163804133558006),\n",
       " ('CIC0', 0.044713833314312355),\n",
       " ('SM1_Dz(Z)', 1.2587188417698731),\n",
       " ('GATS1i', -0.03800927663571632),\n",
       " ('NdsCH', 0.3630734478276748),\n",
       " ('NdssC', 0.004665348846348374),\n",
       " ('MLOGP', 0.39051005215303064),\n",
       " ('FV1', -0.07460286288002355),\n",
       " ('VFV', -0.035706946023729334),\n",
       " ('FV2', -0.015258825830479272),\n",
       " ('FV3', -0.0018031593979083939)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(j, chem_train_aug_beta_ml[i]) for i, j in enumerate(np.concatenate((np.array(['Intercept']), chemistry_samples.columns[:-1].values)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intercept</th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>NdssC</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>FV1</th>\n",
       "      <th>VFV</th>\n",
       "      <th>FV2</th>\n",
       "      <th>FV3</th>\n",
       "      <th>R2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear regression</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.620373</td>\n",
       "      <td>1.680680</td>\n",
       "      <td>-0.566142</td>\n",
       "      <td>0.416241</td>\n",
       "      <td>0.063723</td>\n",
       "      <td>0.430638</td>\n",
       "      <td>0.057044</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.014280</td>\n",
       "      <td>-0.019169</td>\n",
       "      <td>0.771212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>augmented linear regression</th>\n",
       "      <td>2.61638</td>\n",
       "      <td>0.044714</td>\n",
       "      <td>1.258719</td>\n",
       "      <td>-0.038009</td>\n",
       "      <td>0.363073</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.390510</td>\n",
       "      <td>-0.074603</td>\n",
       "      <td>-0.035707</td>\n",
       "      <td>-0.015259</td>\n",
       "      <td>-0.001803</td>\n",
       "      <td>0.871826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Intercept      CIC0  SM1_Dz(Z)    GATS1i  \\\n",
       "linear regression              0.00000  0.620373   1.680680 -0.566142   \n",
       "augmented linear regression    2.61638  0.044714   1.258719 -0.038009   \n",
       "\n",
       "                                NdsCH     NdssC     MLOGP       FV1       VFV  \\\n",
       "linear regression            0.416241  0.063723  0.430638  0.057044  0.001251   \n",
       "augmented linear regression  0.363073  0.004665  0.390510 -0.074603 -0.035707   \n",
       "\n",
       "                                  FV2       FV3  R2 score  \n",
       "linear regression            0.014280 -0.019169  0.771212  \n",
       "augmented linear regression -0.015259 -0.001803  0.871826  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['Intercept'] + list(chemistry_samples.columns[:-1].values) + ['R2 score']\n",
    "data = [[0] + list(chem_train_beta_ml) + [r2_score(chem_train_y, chem_train_ml_prediction_y)],\n",
    "list(chem_train_aug_beta_ml) + [r2_score(chem_train_y, chem_train_aug_ml_prediction_y)]]\n",
    "rows = ['linear regression', 'augmented linear regression']\n",
    "pd.DataFrame(data, index=rows, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.2\n",
    "\n",
    "I have extracted the data from the csv file 'chemistry_test' and carried out the same analysis as the first file above. This confirms the same pattern as before and therefore allows me to carry on with my regression with no need to filtering. I then extract the test parameters to use, along with the test values which will be used to compare the estimates to their actual values. I start by using the original linear regression on the test parameters, using the calculated beta coefficients from the previous part, and then work out its $R^2$ score. The $R^2$ score is 0.76, which is within a variance of the test data, meaning that it is close enough to signify that the model performs at the consistent level for any prediction made. This is because it is a very similar score to its previous score, meaning that the regression is not overfit to the training data and should give global predictions at the same score.\n",
    "\n",
    "I then used the augmented linear regression model to predict the unseen test data and this returned an $R^2$ score of 0.86 which is also very close to its score on the training data. This means that it also has a consistent fit that isn't overfit to the training data. But I also notice that the $R^2$ score for the augmented linear regression is higher on both the in and out of sample data, which indicates that it is a much better fit that the original linear regression model. This would also confirm that the data is not normalised through the origin and such any other models we will fit to the data should include this intercept value also. I have presented the scores in a table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data as pandas data frames\n",
    "chemistry_test = pd.read_csv('chemistry_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>NdssC</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>FV1</th>\n",
       "      <th>VFV</th>\n",
       "      <th>FV2</th>\n",
       "      <th>FV3</th>\n",
       "      <th>LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.617579</td>\n",
       "      <td>0.376167</td>\n",
       "      <td>1.224281</td>\n",
       "      <td>0.849464</td>\n",
       "      <td>1.101738</td>\n",
       "      <td>-0.448372</td>\n",
       "      <td>14.913614</td>\n",
       "      <td>-9.091450</td>\n",
       "      <td>-1.953849</td>\n",
       "      <td>0.328298</td>\n",
       "      <td>1.791786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.278766</td>\n",
       "      <td>0.514788</td>\n",
       "      <td>1.259734</td>\n",
       "      <td>0.210436</td>\n",
       "      <td>0.819626</td>\n",
       "      <td>4.446118</td>\n",
       "      <td>12.904817</td>\n",
       "      <td>-37.986185</td>\n",
       "      <td>-2.804426</td>\n",
       "      <td>0.452758</td>\n",
       "      <td>6.125609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.578652</td>\n",
       "      <td>0.221018</td>\n",
       "      <td>1.552583</td>\n",
       "      <td>1.007153</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>1.960720</td>\n",
       "      <td>17.393050</td>\n",
       "      <td>-27.188863</td>\n",
       "      <td>3.565159</td>\n",
       "      <td>0.341665</td>\n",
       "      <td>3.953270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.021762</td>\n",
       "      <td>1.602774</td>\n",
       "      <td>1.044233</td>\n",
       "      <td>0.054776</td>\n",
       "      <td>2.060890</td>\n",
       "      <td>4.510903</td>\n",
       "      <td>12.777434</td>\n",
       "      <td>-22.710306</td>\n",
       "      <td>-7.966119</td>\n",
       "      <td>1.729511</td>\n",
       "      <td>6.995314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.487163</td>\n",
       "      <td>0.799948</td>\n",
       "      <td>1.005727</td>\n",
       "      <td>0.094923</td>\n",
       "      <td>0.146542</td>\n",
       "      <td>2.298082</td>\n",
       "      <td>13.336721</td>\n",
       "      <td>-16.839870</td>\n",
       "      <td>2.607198</td>\n",
       "      <td>0.904353</td>\n",
       "      <td>5.253633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CIC0  SM1_Dz(Z)    GATS1i     NdsCH     NdssC     MLOGP        FV1  \\\n",
       "0  1.617579   0.376167  1.224281  0.849464  1.101738 -0.448372  14.913614   \n",
       "1  4.278766   0.514788  1.259734  0.210436  0.819626  4.446118  12.904817   \n",
       "2  3.578652   0.221018  1.552583  1.007153 -0.013073  1.960720  17.393050   \n",
       "3  3.021762   1.602774  1.044233  0.054776  2.060890  4.510903  12.777434   \n",
       "4  2.487163   0.799948  1.005727  0.094923  0.146542  2.298082  13.336721   \n",
       "\n",
       "         VFV       FV2       FV3      LC50  \n",
       "0  -9.091450 -1.953849  0.328298  1.791786  \n",
       "1 -37.986185 -2.804426  0.452758  6.125609  \n",
       "2 -27.188863  3.565159  0.341665  3.953270  \n",
       "3 -22.710306 -7.966119  1.729511  6.995314  \n",
       "4 -16.839870  2.607198  0.904353  5.253633  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIC0         float64\n",
       "SM1_Dz(Z)    float64\n",
       "GATS1i       float64\n",
       "NdsCH        float64\n",
       "NdssC        float64\n",
       "MLOGP        float64\n",
       "FV1          float64\n",
       "VFV          float64\n",
       "FV2          float64\n",
       "FV3          float64\n",
       "LC50         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CIC0</th>\n",
       "      <th>SM1_Dz(Z)</th>\n",
       "      <th>GATS1i</th>\n",
       "      <th>NdsCH</th>\n",
       "      <th>NdssC</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>FV1</th>\n",
       "      <th>VFV</th>\n",
       "      <th>FV2</th>\n",
       "      <th>FV3</th>\n",
       "      <th>LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "      <td>1028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.861501</td>\n",
       "      <td>0.631125</td>\n",
       "      <td>1.269849</td>\n",
       "      <td>0.455870</td>\n",
       "      <td>0.494666</td>\n",
       "      <td>2.068875</td>\n",
       "      <td>14.818163</td>\n",
       "      <td>-21.742714</td>\n",
       "      <td>0.584122</td>\n",
       "      <td>0.632418</td>\n",
       "      <td>4.120735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.774397</td>\n",
       "      <td>0.418012</td>\n",
       "      <td>0.382645</td>\n",
       "      <td>0.719690</td>\n",
       "      <td>0.911657</td>\n",
       "      <td>1.450723</td>\n",
       "      <td>3.494455</td>\n",
       "      <td>7.160118</td>\n",
       "      <td>4.700937</td>\n",
       "      <td>0.450990</td>\n",
       "      <td>1.175629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.647476</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.202975</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>-0.540236</td>\n",
       "      <td>-2.441058</td>\n",
       "      <td>5.395300</td>\n",
       "      <td>-49.146675</td>\n",
       "      <td>-26.198937</td>\n",
       "      <td>-0.195405</td>\n",
       "      <td>1.161957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.273664</td>\n",
       "      <td>0.286499</td>\n",
       "      <td>0.967198</td>\n",
       "      <td>0.053715</td>\n",
       "      <td>-0.068329</td>\n",
       "      <td>1.159844</td>\n",
       "      <td>12.140332</td>\n",
       "      <td>-26.549683</td>\n",
       "      <td>-0.594728</td>\n",
       "      <td>0.271490</td>\n",
       "      <td>3.303218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.897980</td>\n",
       "      <td>0.554753</td>\n",
       "      <td>1.222545</td>\n",
       "      <td>0.124618</td>\n",
       "      <td>0.108270</td>\n",
       "      <td>2.088124</td>\n",
       "      <td>14.471913</td>\n",
       "      <td>-21.912708</td>\n",
       "      <td>2.503755</td>\n",
       "      <td>0.533540</td>\n",
       "      <td>4.110352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.411725</td>\n",
       "      <td>0.903278</td>\n",
       "      <td>1.523901</td>\n",
       "      <td>0.871427</td>\n",
       "      <td>0.932910</td>\n",
       "      <td>2.978749</td>\n",
       "      <td>16.934890</td>\n",
       "      <td>-16.346515</td>\n",
       "      <td>3.353090</td>\n",
       "      <td>0.898143</td>\n",
       "      <td>4.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.801678</td>\n",
       "      <td>2.013109</td>\n",
       "      <td>2.699048</td>\n",
       "      <td>4.342691</td>\n",
       "      <td>6.129559</td>\n",
       "      <td>6.679374</td>\n",
       "      <td>28.259679</td>\n",
       "      <td>0.681013</td>\n",
       "      <td>5.618493</td>\n",
       "      <td>2.105268</td>\n",
       "      <td>8.068737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CIC0    SM1_Dz(Z)       GATS1i        NdsCH        NdssC  \\\n",
       "count  1028.000000  1028.000000  1028.000000  1028.000000  1028.000000   \n",
       "mean      2.861501     0.631125     1.269849     0.455870     0.494666   \n",
       "std       0.774397     0.418012     0.382645     0.719690     0.911657   \n",
       "min       0.647476     0.003592     0.202975     0.000323    -0.540236   \n",
       "25%       2.273664     0.286499     0.967198     0.053715    -0.068329   \n",
       "50%       2.897980     0.554753     1.222545     0.124618     0.108270   \n",
       "75%       3.411725     0.903278     1.523901     0.871427     0.932910   \n",
       "max       5.801678     2.013109     2.699048     4.342691     6.129559   \n",
       "\n",
       "             MLOGP          FV1          VFV          FV2          FV3  \\\n",
       "count  1028.000000  1028.000000  1028.000000  1028.000000  1028.000000   \n",
       "mean      2.068875    14.818163   -21.742714     0.584122     0.632418   \n",
       "std       1.450723     3.494455     7.160118     4.700937     0.450990   \n",
       "min      -2.441058     5.395300   -49.146675   -26.198937    -0.195405   \n",
       "25%       1.159844    12.140332   -26.549683    -0.594728     0.271490   \n",
       "50%       2.088124    14.471913   -21.912708     2.503755     0.533540   \n",
       "75%       2.978749    16.934890   -16.346515     3.353090     0.898143   \n",
       "max       6.679374    28.259679     0.681013     5.618493     2.105268   \n",
       "\n",
       "              LC50  \n",
       "count  1028.000000  \n",
       "mean      4.120735  \n",
       "std       1.175629  \n",
       "min       1.161957  \n",
       "25%       3.303218  \n",
       "50%       4.110352  \n",
       "75%       4.822600  \n",
       "max       8.068737  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1028, 11)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chemistry_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the test set\n",
    "chem_test = chemistry_test.iloc[:, :-1].values\n",
    "\n",
    "# define the test target values\n",
    "chem_test_y = chemistry_test.iloc[:, -1].values\n",
    "\n",
    "# predict the function values at the test points using the maximum likelihood estimator\n",
    "chem_test_ml_prediction_y = predict_with_estimate(chem_test, chem_train_beta_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.7617663939067444\n"
     ]
    }
   ],
   "source": [
    "print(r'R2 score:', r2_score(chem_test_y, chem_test_ml_prediction_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the augmented test set \n",
    "chem_test_aug = np.hstack([np.ones((chem_test.shape[0],1)), chem_test])\n",
    "\n",
    "# predict the function values at the test points using the augmented maximum likelihood estimator\n",
    "chem_test_aug_ml_prediction_y = predict_with_estimate(chem_test_aug, chem_train_aug_beta_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.8642933369927278\n"
     ]
    }
   ],
   "source": [
    "print(r'R2 score:', r2_score(chem_test_y, chem_test_aug_ml_prediction_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In-sample R2 score</th>\n",
       "      <th>Out-of-sample R2 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear regression</th>\n",
       "      <td>0.771212</td>\n",
       "      <td>0.761766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>augmented linear regression</th>\n",
       "      <td>0.871826</td>\n",
       "      <td>0.864293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             In-sample R2 score  Out-of-sample R2 score\n",
       "linear regression                      0.771212                0.761766\n",
       "augmented linear regression            0.871826                0.864293"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['In-sample R2 score', 'Out-of-sample R2 score']\n",
    "data = [[r2_score(chem_train_y, chem_train_ml_prediction_y), r2_score(chem_test_y, chem_test_ml_prediction_y)],\n",
    "[r2_score(chem_train_y, chem_train_aug_ml_prediction_y), r2_score(chem_test_y, chem_test_aug_ml_prediction_y)]]\n",
    "rows = ['linear regression', 'augmented linear regression']\n",
    "pd.DataFrame(data, index=rows, columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpbJPhupy0Cj"
   },
   "source": [
    "<a name=\"q12\"></a>\n",
    "## 1.2 [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_estimate(X, y, penalty):\n",
    "    \n",
    "    # X: N x D matrix of training inputs\n",
    "    # y: N x 1 vector of training targets/observations\n",
    "    # returns: maximum likelihood parameters (D x 1)\n",
    "    \n",
    "    N, D = X.shape\n",
    "    X_aug = np.hstack([np.ones((N,1)), X]) # augmented training inputs of size N x (D+1)\n",
    "    N_aug, D_aug = X_aug.shape\n",
    "    I = np.identity(D_aug)\n",
    "    #I[0,0] = 0\n",
    "    beta_ridge = np.linalg.solve(X_aug.T @ X_aug + penalty * I, X_aug.T @ y).reshape(-1,1)\n",
    "    return beta_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train set\n",
    "chem_train = chemistry_samples.iloc[:, :-1].values\n",
    "\n",
    "# define the augmented test set \n",
    "chem_train_aug = np.hstack([np.ones((chem_train.shape[0],1)), chem_train])\n",
    "\n",
    "# define the train target values\n",
    "chem_train_y = chemistry_samples.iloc[:, -1].values\n",
    "\n",
    "# set penalty\n",
    "penalty = 1\n",
    "\n",
    "# work out the augmented maximum likelihood estimates\n",
    "chem_train_beta_ridge = ridge_estimate(chem_train, chem_train_y, penalty)\n",
    "\n",
    "# predict the function values at the test points using the augmented maximum likelihood estimator\n",
    "chem_train_ridge_prediction_y = predict_with_estimate(chem_train_aug, chem_train_beta_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: -7696.973849818741\n"
     ]
    }
   ],
   "source": [
    "print(r'R2 score:', r2_score(chem_train_y, chem_train_ridge_prediction_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_ridge_MSE(X_train, y_train, X_test, y_test, penalty):\n",
    "    \n",
    "    # X_train: 4M x D matrix of training inputs\n",
    "    # y_train: 4M x 1 vector of training targets\n",
    "    # X_test: M x D matrix of test inputs\n",
    "    # y_test: M x 1 vector of test targets\n",
    "    # returns: MSE of the ridge prediction\n",
    "    \n",
    "    beta_aug = ridge_estimate(X_train, y_train, penalty)\n",
    "    X_test_aug = np.hstack([np.ones((X_test.shape[0],1)), X_test])\n",
    "    y_pred = predict_with_estimate(X_test_aug, beta_aug)\n",
    "    return np.mean((y_test-y_pred)**2)\n",
    "\n",
    "\n",
    "def cross_validation_score_ridge(X_train, y_train, folds, penalty):\n",
    "    \n",
    "    # X_train: N x D matrix of training inputs\n",
    "    # y_train: N x 1 vector of training targets\n",
    "    # folds: f x N/f matrix of indexes to cross validate\n",
    "    # penalty: float of the penalty for ridge regression\n",
    "    # returns: average MSE score for the given penalty ridge regression\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(len(folds)):\n",
    "        val_indexes = folds[i]\n",
    "        train_indexes = list(set(range(y_train.shape[0])) - set(val_indexes))\n",
    "    \n",
    "        X_train_i = X_train[train_indexes, :]\n",
    "        y_train_i = y_train[train_indexes]\n",
    "\n",
    "        X_val_i = X_train[val_indexes, :]\n",
    "        y_val_i = y_train[val_indexes]\n",
    "\n",
    "        score_i = score_ridge_MSE(X_train_i, y_train_i, X_val_i, y_val_i, penalty)\n",
    "        scores.append(score_i)\n",
    "    \n",
    "    # Return the average score\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "\n",
    "def choose_best_penalty(X_train, y_train, folds, penalty_range):\n",
    "    \n",
    "    # X_train: N x D matrix of training inputs\n",
    "    # y_train: N x 1 vector of training targets\n",
    "    # folds: f x N/f matrix of indexes to cross validate\n",
    "    # penalty_range: M x 1 vector of penalty values to test\n",
    "    # returns: lowest average MSE penalty value from penalty range\n",
    "    \n",
    "    penalty_scores = np.zeros((len(penalty_range),))\n",
    "\n",
    "    for i, penalty in enumerate(penalty_range):\n",
    "        penalty_scores[i] = cross_validation_score_ridge(X_train, y_train, folds, penalty)\n",
    "        print(f'CV_ACC@penalty={penalty}: {penalty_scores[i]:.3f}')\n",
    "\n",
    "    best_penalty_index = np.argmin(penalty_scores)\n",
    "    return penalty_range[best_penalty_index]\n",
    "\n",
    "\n",
    "def define_folds_indexes(y_test, folds):\n",
    "    \n",
    "    # y_test: N x 1 vector of training targets\n",
    "    # folds: integer of the number of folds wanted\n",
    "    # returns: the folds indexes for the parameters given\n",
    "    \n",
    "    return np.split(np.arange(len(y_test)), [int(x*len(y_test)/folds) for x in range(1, folds)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV_ACC@penalty=0.0: 2.723\n",
      "CV_ACC@penalty=0.05263157894736842: 2.723\n",
      "CV_ACC@penalty=0.10526315789473684: 2.723\n",
      "CV_ACC@penalty=0.15789473684210525: 2.723\n",
      "CV_ACC@penalty=0.21052631578947367: 2.723\n",
      "CV_ACC@penalty=0.2631578947368421: 2.723\n",
      "CV_ACC@penalty=0.3157894736842105: 2.723\n",
      "CV_ACC@penalty=0.3684210526315789: 2.723\n",
      "CV_ACC@penalty=0.42105263157894735: 2.723\n",
      "CV_ACC@penalty=0.47368421052631576: 2.723\n",
      "CV_ACC@penalty=0.5263157894736842: 2.723\n",
      "CV_ACC@penalty=0.5789473684210527: 2.723\n",
      "CV_ACC@penalty=0.631578947368421: 2.723\n",
      "CV_ACC@penalty=0.6842105263157894: 2.723\n",
      "CV_ACC@penalty=0.7368421052631579: 2.723\n",
      "CV_ACC@penalty=0.7894736842105263: 2.723\n",
      "CV_ACC@penalty=0.8421052631578947: 2.723\n",
      "CV_ACC@penalty=0.894736842105263: 2.722\n",
      "CV_ACC@penalty=0.9473684210526315: 2.722\n",
      "CV_ACC@penalty=1.0: 2.722\n",
      "best_penalty: 1.0\n"
     ]
    }
   ],
   "source": [
    "# define the train set\n",
    "chem_train = chemistry_samples.iloc[:, :-1].values\n",
    "\n",
    "# define the train target values\n",
    "chem_train_y = chemistry_samples.iloc[:, -1].values\n",
    "\n",
    "# choose the number of folds wanted, in the question it is 5\n",
    "folds = 5\n",
    "\n",
    "# define the fold indexes to be used in the cross validation\n",
    "folds_indexes = define_folds_indexes(chem_train_y, folds)\n",
    "\n",
    "# define the penalty range to test\n",
    "penalty_range = np.linspace(0, 1, 20)\n",
    "\n",
    "# work out the best penalty\n",
    "best_penalty = choose_best_penalty(chem_train, chem_train_y, folds_indexes, penalty_range)\n",
    "print('best_penalty:', best_penalty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9OTrzYly0Oz"
   },
   "source": [
    "<a name=\"q13\"></a>\n",
    "\n",
    "## 1.3 [^](#outline)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P63G41hE0Xiz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JV3UJe2A0IH-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg2TWPoT0J0Z"
   },
   "outputs": [],
   "source": [
    "def huber(beta, c=1e-6):\n",
    "    return None  # <-- EDIT THIS LINE\n",
    "  \n",
    "def grad_huber(beta, c=1e-6):\n",
    "    return None  # <-- EDIT THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7hMrAxK0LQN"
   },
   "outputs": [],
   "source": [
    "def minimize_ls_huber(X, y, lambd, n_iters=10000, step_size=1e-3):\n",
    "    n, p = X.shape\n",
    "    XX = X.T @ X / n\n",
    "    Xy = X.T @ y / n\n",
    "    \n",
    "    # next line: initialise betas\n",
    "    beta = np.zeros(shape=(p, 1))\n",
    "\n",
    "    # gradient descent (hint: see logistic regression coding task)\n",
    "    for i in range(n_iters):\n",
    "        grad = None  # <-- EDIT THIS LINE\n",
    "        # next line: gradient descent update\n",
    "        beta = None  # <-- EDIT THIS LINE\n",
    "      \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oi0I8ERdy0mD"
   },
   "source": [
    "<a name=\"task-2\"></a>\n",
    "\n",
    "# Task 2: Classification [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgBfTmgpy08Z"
   },
   "source": [
    "<a name=\"q21\"></a>\n",
    "\n",
    "## 2.1 [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCPlajQOy1ER"
   },
   "source": [
    "<a name=\"q22\"></a>\n",
    "\n",
    "## 2.2 [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfN9uz1qy1L4"
   },
   "source": [
    "<a name=\"q23\"></a>\n",
    "\n",
    "## 2.3 [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlwygRTDy1fb"
   },
   "source": [
    "<a name=\"task-3\"></a>\n",
    "\n",
    "# Task 3: Mastery Component [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdYowG2Ny1qx"
   },
   "source": [
    "<a name=\"q31\"></a>\n",
    "\n",
    "## 3.1 [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XbuLm6qy100"
   },
   "source": [
    "<a name=\"q32\"></a>\n",
    "\n",
    "## 3.2 [^](#outline)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SurnameCID_CW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
